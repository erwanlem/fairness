\documentclass{article}
\usepackage[T1]{fontenc}

\usepackage{graphicx}
\usepackage{parskip}
\usepackage{xcolor}
\usepackage[colorlinks=true,linkcolor=black]{hyperref}
\usepackage[french]{babel}
\usepackage{subcaption}
\usepackage[french]{babel}

\usepackage[margin=3.5cm]{geometry}


\author{Erwan LEMATTRE, Yannis CHUPIN}
\title{Rapport mi-projet\\Fairness pour l'IA}

\begin{document}
    \maketitle
    \newpage
    \tableofcontents
    \newpage

    \section{Introduction}
    Ce projet a pour objectif d'analyser les accidents de la circulation routière afin de pouvoir déterminer 
    à partir des données d'un véhicule accidenté si l'accident est mortel ou non.
    Les données sont des données libres mises à disposition par le \textit{Ministère de l'Intérieur et des 
    Outre-Mer}. Le jeu de données correspond aux accidents de 2005 à 2022 en France. Nous allons, dans une première 
    partie, analyser ces données afin d'extraire les informations utiles à l'apprentissage. Puis nous essaierons de repérer 
    d'éventuelles sources de biais affectant notre modèle.
    
    Vous pouvez retrouver le code sur le GitHub du projet. Le fichier \texttt{main.ipynb} contient 
    le code principal que nous allons suivre et contextualiser tout au long de ce rapport. de plus, le fichier \texttt{utils.py} 
    contient toutes les fonctions auxiliaires que nous utilisons dans le fichier principal.

    \newpage
    \part{Analyse}
    \section{Découverte du jeu de données}
    \subsection{La base de données}
    La base de données est composée de plusieurs tables : \textit{usagers}, \textit{véhicules}, \textit{lieux} et 
    \textit{caractéristiques}. Nous avons joint ces quatre parties pour obtenir un dataframe contenant une 
    cinquantaine de colonnes. 
    On peut retrouver une partie des attributs dans l'annexe \ref{appendix:dataset}.


    \subsection{Répartition des données}
    Afin de pouvoir conserver les données utiles pour l'apprentissage, nous avons analysé la répartition des 
    différentes données dans notre dataframe.
    Nous avons ainsi pu faire différentes observations. 
    \\
    Voici quelques-unes d'entre elles qui nous sont ensuite utiles pour la préparation des données.
    \subsubsection{Catégories de véhicule}
    La base de données contient beaucoup de types de véhicules différents. Nous avons cependant pu remarquer 
    que la majorité des véhicules sont dans seulement 5 catégories.
    \begin{figure}[ht]
        \centering
        \includegraphics[width=12cm]{./img/catv1.png}
        \caption{Répartition des catégories de véhicules}
    \end{figure}

    \subsubsection{Gravité de l'accident}
    En affichant l'effectif d'individus décédés dans un accident, nous avons pu remarquer qu'ils ne représentent qu'une 
    infime partie des individus accidentés. Leur proportion est si fable que ça ne nous permet pas d'apprendre 
    un modèle. C'est la raison pour laquelle nous avons décidé de nous intéresser non pas à la mortalité 
    à l'échelle d'une personne, mais plutôt à l'échelle d'un accident. Nous nous mettons pour cela au niveau d'un 
    véhicule car cela nous permet de conserver plus d'informations (à l'échelle d'un accident, on aurait 
    dû enlever trop d'informations pour ne conserver que les attributs plus généraux à l'accident).

    \begin{figure}[ht]
        \centering
        \includegraphics[width=12cm]{./img/grav1.png}
        \caption{Proportion d'accidents mortels}
    \end{figure}

    \section{Préparation des données}
    À partir des observations précédentes, nous avons supprimé les attributs moins intéressants pour l'apprentissage 
    et nous avons modifié certains attributs afin d'en extraire les informations intéressantes.
    \\
    Les attributs supprimés sont : \textit{voie}, \textit{v1}, \textit{v2}, \textit{pr}, \textit{pr1}, \textit{lartpc},
    \textit{larrout}, \textit{num\_veh}, \textit{occutc}, \textit{adr}, \textit{senc}, \textit{etatp}, \textit{actp}, 
    \textit{manv}, \textit{jour}, \textit{com}, \textit{hrmn}, \textit{motor}, \textit{place}, \textit{vosp}, \textit{locp}.
    \\\\
    Nous avons effectué les modifications suivantes :
    \begin{itemize}
        \item Création d'un attribut \textit{mortal} qui vaut 1 si le véhicule est impliqué dans un accident mortel, 0 sinon.
        \item À partir de l'attribut \textit{sexe}, nous avons créé un attribut \textit{sexe\_conducteur} qui garde seulement 
                le sexe du conducteur du véhicule.
        \item Création d'un attribut \textit{piéton} qui vaut 1 si un piéton est impliqué dans l'accident, sinon 0.
        \item Nous avons utilisé l'année de naissance et l'année de l'accident pour récupérer l'âge du conducteur.
        \item L'attribut \textit{vma} a été découpé en 4 catégories de vitesse.
        \item Pour les attributs \textit{catv} et \textit{catr}, nous avons gardé les valeurs les plus représentées dans la base de données.
    \end{itemize}
    \vspace{0.5cm}
    Nous avons également réduit les valeurs de certains attributs. Par exemple, pour des attributs 
    avec des valeurs telles que \textit{Non-renseigné}, \textit{Autre}, \dots \, nous avons regroupé 
    ces valeurs en une seule valeur. L'objectif était ici de simplifier en réduisant les catégories 
    mais également d'améliorer les performances de notre modèle.

    \section{Analyse des données}
    Une fois nos données préparées, nous avons pu les visualiser. Nous allons montrer dans les 
    deux prochaines parties les observations intéressantes que nous avons pu faire lors de 
    l'analyse de notre dataset.
    
    \subsection{Analyse univariée des données}
    \subsubsection{Les accidents mortels}
    Une donnée intéressante à observer est la proportion de véhicules impliqués dans un accident 
    mortel. C'est en effet la valeur que nous voulons prédire.

    \begin{figure}[ht]
        \centering
        \includegraphics[width=10cm]{./img/grav2.png}
        \caption{Proportion des véhicules impliqués dans un accident mortel}\label{fig:fig_acc_mortel}
    \end{figure}

    Nous pouvons remarquer sur la figure \ref{fig:fig_acc_mortel} que le fait de s'intéresser 
    aux véhicules impliqués dans un accident mortel et non plus aux personnes nous permet 
    de doubler ce pourcentage. Même si cette proportion reste faible, cela va nous permettre 
    d'avoir plus de données dans la catégorie mortelle lors de l'apprentissage et par conséquent 
    d'avoir un meilleur modèle.

    \subsubsection{Les piétons}
    Nous nous sommes ensuite intéressés aux accidents dans lesquels un piéton est impliqué. 
    La figure \ref{fig:fig_acc_pieton} nous montre qu'un peu moins de 10\% des accidents impliquent 
    un piéton.

    \begin{figure}[ht]
        \centering
        \includegraphics[width=10cm]{./img/pieton.png}
        \caption{Proportion des accidents avec piéton}\label{fig:fig_acc_pieton}
    \end{figure}

    \subsubsection{L'âge}
    Nous pouvons visualiser l'âge des conducteurs via une boîte à moustache. La figure \ref{fig:fig_age} nous 
    montre la répartition de l'âge des conducteurs. Lors du prétraitement des données, les valeurs aberrantes 
    ont été enlevées. On retrouve donc logiquement des âges contenus entre 0 et 100 ans. L'âge médian des 
    conducteurs est 33 ans avec le premier quartile à 21 et le troisième quartile à 49 ans. Même si on peut 
    imaginer que des valeurs sont fausses (il y a des conducteurs de moins de 16 ans), les valeurs sont tout de 
    même assez cohérentes par rapport à ce que l'on pourrait imaginer de la répartition de l'âge des conducteurs.

    \begin{figure}[ht]
        \centering
        \includegraphics[width=12cm]{./img/age.png}
        \caption{Âge des conducteurs}\label{fig:fig_age}
    \end{figure}

    \subsubsection{Le genre des conducteurs}
    Le genre des conducteurs est assez intéressant à analyser. Sur la figure \ref{fig:fig_genre}, nous pouvons 
    remarquer une différence importante entre le nombre de femmes au volant d'un véhicule ayant eu un accident 
    (indice 0) et le nombre d'hommes (indice 1). Cette différence pourrait être une source de biais pour notre modèle. 
    En effet, le fait qu'il y ait beaucoup plus de données d'accident avec des hommes ne signifie pas qu'il y a plus 
    de chances d'avoir un accident si on est un homme. Cela signifie peut-être que la proportion d'hommes au volant 
    est plus élevée et donc qu'il y a plus d'accidents avec un homme au volant car il y a plus d'hommes au volant. Le 
    risque ici est que moins de données avec des femmes conduisent à des prédictions plus marquées pour les femmes et 
    par conséquent à des potentiels biais.

    \begin{figure}[ht]
        \centering
        \includegraphics[width=12cm]{./img/sexe.png}
        \caption{Genre des conducteurs}\label{fig:fig_genre}
    \end{figure}

    \subsubsection{Le type de collision}
    La figure \ref{fig:fig_col} montre la répartition des différents types de collisions dans notre dataset. On peut 
    remarquer que tous les types de collisions sont plutôt bien représentés dans notre dataset. C'est un attribut qui 
    pourra être assez intéressant pour l'apprentissage.

    \begin{figure}[ht]
        \centering
        \includegraphics[width=12cm]{./img/col.png}
        \caption{Les types de collision}\label{fig:fig_col}
    \end{figure}

    \subsection{Analyse bivariée des données}
    Nous allons dans cette partie donner quelques exemples intéressants obtenus lors de l'analyse bivariée. On 
    peut retrouver l'ensemble des graphiques observés dans le fichier \texttt{main.ipynb}.

    \subsubsection{Le genre du conducteur}
    Un attribut qu'il est intéressant d'analyser est le genre du conducteur. En effet, il peut être source de biais 
    s'il y a un déséquilibre entre hommes et femmes.
    On retrouve globalement la même proportion dans la corrélation que l'on soit homme ou femme. Les hommes étant 
    beaucoup plus représentés dans le dataset, la proportion d'hommes est logiquement plus élevée. On peut cependant 
    faire quelques remarques. 
    
    La figure \ref{fig:fig_sexe_bivar1} nous montre une proportion de femmes moins élevée quand \textit{obsm} vaut 
    \textit{6}. La proportion de femmes est deux fois plus élevée quand \textit{obsm} vaut \textit{1}. Ceci pourrait biaiser notre 
    modèle.
    
    Sur la figure \ref{fig:fig_sexe_bivar2}, on remarque également une proportion différente de femmes 
    en fonction du type de véhicule. On pourrait expliquer cela par le fait que certains véhicules sont 
    dans la réalité plus utilisés par les hommes, par exemple on pourrait imaginer qu'il y a plus d'hommes qui 
    conduisent des motos. Il faudra être vigilant car cela peut être source de biais. Il se peut que notre 
    modèle associe une moto à un homme. Dans le cas d'une femme sur une moto le résultat pourrait être soit
    forcément un accident mortel, ou bien forcément un accident non mortel.

    \begin{figure}[h]
        \centering
        \begin{subfigure}{7cm}
            \includegraphics[width=7cm]{./img/bivar_sexe.png}
            \caption{Proportion femmes/hommes en fonction de la présence d'un obstacle dans l'accident}\label{fig:fig_sexe_bivar1}
        \end{subfigure}
        \hspace{0.2cm}
        \begin{subfigure}{7cm}
            \includegraphics[width=7cm]{./img/bivar_sexe2.png}
        \caption{Proportion femmes/hommes en fonction de la catégorie du véhicule}\label{fig:fig_sexe_bivar2}
        \end{subfigure}
    \end{figure}
    \vspace{2cm}

    \subsubsection{L'âge du conducteur}
    On peut remarquer sur la figure \ref{fig:fig_age_bivar} que la probabilité d'accident mortel est beaucoup plus élevée à l'âge de 
    21 ans. Cela est dû en partie au fait que les conducteurs de 21 ans sont surreprésentés. Cette probabilité risque de poser 
    problème pour notre modèle. En effet l'âge n'est pas un paramètre déterminant dans l'évaluation de la gravité de l'accident. 
    Le problème est que notre modèle va probablement associer l'âge de 21 ans à un accident mortel, peu importe les autres paramètres 
    de l'accident. L'âge serait donc notre \textbf{attribut sensible}.

    \begin{figure}[ht]
        \centering
        \includegraphics[width=14cm]{./img/bivar_age.png}
        \caption{Analyse bivariée âge -- accident mortel}\label{fig:fig_age_bivar}
    \end{figure}
    
    \section{Apprentissage}
    
    \subsection{Split}
    Séparer nos données en deux ensembles demandait de tenir compte d'une spécificité. Nous nous plaçons du point de vue d'un véhicule, 
    mais bien souvent, plusieurs véhicules sont impliqués dans un  même accident. Il nous a donc fallu adapter le split pour que les 
    véhicules d'un même accident soient dans le même ensemble. 
    
    Par ailleurs, nous avons constaté que, si on ne le faisait pas, un surapprentissage lors du test se produisait. Typiquement, un trop grand 
    nombre de morts étaient correctement prédits. Mais le modèle trouvait une partie de ces véhicules en les associant à ceux avec lesquels
    ils avaient eu un accident dans l'ensemble d'apprentissage. 
    
    \subsection{Encodage One Hot}
    La base de données nous fournit, pour la plupart des attributs, des données qui peuvent être converties en entiers. 
    Par exemple, une catégorie de véhicule (\textit{catv}) est désignée par un chiffre. L'attribut reste cependant catégoriel. En pratique, 
    les seuls attributs quantitatifs qui nous restent sont l'âge du conducteur, les mois et les départements. 
    Le reste est soit binaire, soit qualitatif. 
    
    Tous les attributs qualitatifs ont donc été transformés en OneHot. Initialement, nous souhaitions optimiser le nombre de colonnes en 
    réalisant les OneHot nous-mêmes. Par exemple, prenons "surf" (l'état de la surface de la route). Il est inutile de créer une colonne 
    pour "Non-renseigné", "Autre" ou "normale". Nous sommes uniquement intéressés par les états spécifiques de la route. 
    
    Cependant, cette approche posait des problèmes car elle empêchait la réalisation de l'audit. Nous avons donc utilisé la méthode 
    standard pour nos OneHot. 
    
    \subsection{Arbre de décision}
    Une fois les données prêtes, nous avons utilisé le classifieur par arbres de décision pour obtenir un modèle. C'est le premier que nous 
    avons utilisé. En ce qui concerne les résultats, le score d'accuracy est de \textit{1} pour l'entraînement et de \textit{0.9014} pour le test.
        
    En ce qui concerne la matrice de confusion, on remarque que \textit{27687} véhicules ont été classés correctement en tant qu'accidents non létaux.
    Tandis que \textit{291} accidents mortels seulement ont été correctement identifiés. Cependant, \textit{1413} accidents mortels ont été recensés à tort 
    comme étant non létaux et \textit{1648} véhicules ont subi le sort inverse. 
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{./img/matrice_confusion_tree.png}
        \caption{La matrice de confusion pour le classifieur d'arbres aléatoires}
    \end{figure}
    

    En résumé, on remarque que le modèle réussit très bien à classifier les accidents qui n'ont pas conduit à la mort de quelqu'un. Cependant, 
    il lui apparaît bien plus difficile de trouver les véhicules impliqués dans des accidents mortels. On peut attribuer ceci au fait que ces 
    accidents létaux ne représentent que \textit{5.38\%} des véhicules accidentés répertoriés dans la base.

    \subsection{GaussianNB}
    Avancés dans le projet, nous avons voulu tester plusieurs classifieurs, tous ont donnés des résultats différents, pour certains médiocres. 
    Mais nous avons trouvé un autre classifieur qui donnait des résultats intéressants : GaussianNB.
        
    Il ne maximise pas notre accuracy score puisqu'il n'est que de \textit{0.8734} à l'entraînement et de \textit{0.8677} pour les tests. Ce qui 
    a toutefois retenu notre attention, c'est le nombre d'accidents létaux qu'il parvient à détecter : \textit{508}. Réduisant ainsi l'erreur associée
    (les accidents mortels recensés à tort comme étant non létaux) à seulement \textit{1196}. Ceci s'accompagne malheureusement une perte de performances 
    pour ce qui est de la détection d'accidents non mortels comme on peut le voir ci-dessous.

    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{./img/matrice_confusion_gaussien.png}
        \caption{La matrice de confusion avec GaussianNB}
    \end{figure}

    Un autre avantage qui peut ressembler à un inconvénient au départ est que ce classifieur demande des nombres et non des OneHot.
    Nos valeurs au départ sont en format numérique, rendant donc nos données compatibles avec cette approche.
    Ceci nous ouvre alors la possibilité de tester d'autres choses puisque le classifieur donne des probabilités et non des arbres. Au premier 
    rang desquels \textit{xplique}.
        
    Par souci de concision cependant, nous prendrons le modèle issu du \textit{tree classifier} pour tous les audits qui vont suivre, 
    puisque c'est le premier avec lequel nous avons travaillé. On notera tout de même que lorsqu'on effectue ces audits avec \textit{GaussianNB}, 
    les résultats diffèrent en bien des points de ceux observés avec le \textit{tree classifier}, preuve qu'ils ont une approche bien différente.

    \subsection{Base Rate}

    Nous avons voulu mesurer les résultats méritant potentiellement une protection : le fait qu'un piéton soit impliqué dans 
    un accident et le sexe du conducteur. Voici les résultats :

    \begin{itemize}
        \item \textbf{Sexe du conducteur} 1 (un homme)
        \item \textbf{Disparate Impact} : 1.21767750298587 1.6331199049428085
        \item \textbf{P-rule disparate Impact} : 0.8212355057458954 0.6123249107266375
        \item \textbf{Démographie Parité} : 0.011747835864606336 0.02383701239031672
    \end{itemize}

    Ce qui est flagrant ici, c'est qu'il existe une disparité dans la prédiction d'accidents mortels pour les hommes. Allant par ailleurs
    dans le sens de ce qu'indique Disparate Impact par la suite. Notons cependant que la disparité démographique entre hommes et femmes
    existe mais est très faible.

    \begin{itemize}
        \item \textbf{Piéton} 1 (un piéton est impliqué)
        \item \textbf{Disparate Impact} : 1.0538191011165416 1.0968113720110815
        \item \textbf{P-rule Disparate Impact} : 0.9489294689576994 0.9117337999207913
        \item \textbf{Démographie Parité} : 0.003345154811069756 0.005266913173450724
    \end{itemize}

    Pour ce qui est de l'implication d'un piéton dans un accident, on constate ici aussi une légère disparité, soulignant leur
    plus grande implication dans des accidents mortels. Ceci concorde encore une fois avec le \textit{disparate Impact}. Démographiquement, 
    le cas est similaire au sexe, puisqu'on constate une légère disparité en leur faveur, bien que cette fois la disparité soit plus
    faible encore.

    \section{Audit du modèle}

    \subsection{Génération des contrefactuels avec Dice}
    Dice nous a permis d'établir quels attributs influent sur la prédiction de notre modèle. Les résultats sont 
    cependant assez variables d'une exécution à l'autre. On peut tout de même retrouver lesquels sont fréquemment impliqués 
    dans le changement des exemples contrefactuels.
    Parmi eux, on peut noter que l'attribut \textit{âge} est souvent représenté. Le taux d'accidents (notamment mortels) étant plus 
    élevé chez les jeunes et les personnes âgées, cela paraît assez cohérent. L'attribut \textit{obsm} est également 
    souvent utilisé dans les exemples contrefactuels.
    Nous avons pu remarquer que l'attribut \textit{col} est peu représenté dans les résultats, contrairement à l'hypothèse que 
    nous avions pu faire lors de l'analyse.

    Enfin, les attributs \textit{dep} et \textit{sexe\_conducteur} sont également représentés. Ils pourraient être sources de biais, notamment 
    l'attribut \textit{dep} ; le modèle pourrait associer un département à une prédiction d'accident mortel.


    \subsection{BlackBoxAuditing}
    Les résultats que nous allons analyser sont issus du modèle généré par \textit{tree classifier}.

    Tout d'abord, l'audit a porté sur les 24 features que nous avons conservé afin d'élaborer ce modèle. 
    On constate tout d'abord le rôle prédominant de l'âge pour l'accuracy score. À \textit{0.84}, ce dernier éclipse 
    tous les autres. Une explication pourrait venir de ce que nous avons constaté dans notre analyse univariée : il y a une 
    surreprésentation des jeunes de 20--21 ans dans ce set. Ceci est en réalité loin de surprendre puisqu'il s'aligne avec la 
    politique de prix pratiquée par les assureurs envers les jeunes conducteurs.

    Par la suite, on peut s'intéresser à l'évolution de l'accuracy en fonction du niveau de réparation appliqué à chaque 
    attribut :

    \begin{figure}[h]
        \centering
        \includegraphics[width=10cm]{./img/accuracy.png}
        \caption{L'accuracy en fonction du niveau de réparation pour chaque attribut.}
    \end{figure}

    On reconnaît toput de suite les 
    attributs dont l'accuracy est au plus haut en regardant ceux qui s'effondrent le plus. En premier lieu, l'âge s'illustre
    à nouveau. À la lumière de ceci, il apparaît évident que le modèle discrimine fortement les véhicules en fonction de l'âge du 
    conducteur. Dans une moindre mesure, on constate la même chose pour \textit{situ}, qui fait référence à la localisation 
    géographique de l'accident. Ce qui paraît sensé, étant donné que certains lieux sont plus dangereux que d'autres. Enfin, 
    on observe que le type d'intersection et la catégorie du véhicule sont également sources de discriminations de la part de notre 
    modèle. Encore une fois, cela semble cohérent.

    Toutefois, notons l'absence de quelques attributs notables tels que le nombre de voies, le sexe du conducteur (chose intéressante :
    ce n'est pas le cas avec GaussianNB), le type de collision, le type d'obstacle heurté ou encore le fait qu'un piéton soit impliqué.
    
    Maintenant regardons l'équilibre du modèle à l'aide du BCR.

    \begin{figure}[h]
        \centering
        \includegraphics[width=10cm]{./img/BCR.png}
        \caption{Le BCR en fonction du niveau de réparation pour chaque attribut.}
    \end{figure}

    On remarque ici que les attributs sont plutôt centrés autour de \textit{0.5} et que la plupart reste rectiligne, mais que certains divergent
    quelque peu. Cet évasement est dû à des attributs déjà connus tels que \textit{âge} ou \textit{catv}. D'autres influent aussi mais ne s'étaient pas 
    illustrés précédemment, à l'image du nombre de voies (\textit{nbv}), du profil de la route (\textit{plan}) ainsi que de la luminosité (\textit{lum}). 

    Malgré cela, l'évasement assez faible laisse penser que le modèle est plutôt équilibré. De plus, comme mentionné précédemment 
    dans la section dédiée au split, nous avons pu tester le cas où l'on acceptait que des véhicules impliqués dans le même accident
    se retrouvent dans des ensembles différents (entraînement / test). Ce qu'il ressortait alors du BCR était un évasement beaucoup
    plus important et une origine située vers 0.68. Ce qui laisse à penser que cette version était bel et bien trop modelée sur le train
    set, l'équilibre était rompu.

    Pour conclure, BlackBoxAuditing nous a permis de comprendre quels étaient les attributs les plus discriminés. Âge est certainement le plus notable.

    \subsection{Expliquer le modèle avec les valeurs de Shapley}
    Afin d'analyser la contribution des différents attributs dans notre modèle, nous avons 
    utilisé les valeurs de Shapley. Nous avons d'abord essayé de calculer la valeur exacte avec la fonction 
    \verb|ShapleyValues| du module \textit{ShapKit}. Cependant, le nombre d'attributs de notre dataset est trop 
    important et le calcul trop long.
    Il a donc fallu calculer une approximation de la valeur de Shapley avec la fonction \verb|MonteCarloShapley|.
    Nous devons cependant être prudents car ce calcul de l'approximation nous 
    donne une tendance pour notre modèle mais certainement pas une valeur exacte. On peut le constater en changeant 
    le nombre d'itérations, qui produit souvent un résultat différent. Toutes les approximations ont ici été calculées 
    avec \texttt{n\_iter=1000}.

    Le temps de calcul étant encore assez long nous avons parallélisé le calcul des valeurs de Shapley. Les calculs 
    ont ensuite été séparés en deux, d'un côté pour les prédictions qui donnent 1 et de l'autre pour celles qui donnent 0.
    ON peut ainsi avoir une idée des attributs décisifs dans les deux cas.

    Ce qui ressort des résultats obtenus est que les attributs \textit{col}, \textit{choc}, \textit{obsm}, \textit{int} 
    et \textit{agg} contribuent souvent au résultat. Ce résultat paraît plutôt cohérent.
    En revanche, on retrouve également assez souvent les attributs \textit{mois}, \textit{âge} et \textit{dep}. Ces 
    attributs ne devraient pas contribuer autant à la sortie de notre modèle. Il peuvent constituer un biais (ce n'est 
    pas parce qu'on a un accident à l'âge de 21 ans que l'on va forcément mourir, d'autres attributs sont beaucoup plus 
    importants).


    Pour l'attribut \textit{sexe\_conducteur} on nous donne une contribution 
    nulle de cet attribut. Cela peut nous encourager dans l'idée que le sexe n'est pas un biais pour notre modèle 
    conrairement à ce que nous pouvions penser au départ.

    Ci-dessous un résultat obtenu du calcul des valeurs de Shapley. Vous pouvons retrouver un échantillon des résultats dans l'annexe ? de ce rapport.
    
    

    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{./img/shap1.png}
        \caption{Une approximation des valeurs de Shapley}
        \label{fig:fig_shap}
    \end{figure}

    \subsection{Expliquer le modèle avec Lime}
    Nous avons également utilisé \textit{Lime} afin d'avoir une idée des attributs qui contribuent
    le plus aux prédictions de notre modèle. On peut retrouver le code correspondant dans le fichier 
    \texttt{lime.ipynb}.

    Nous avons d'abord récupéré les indices des prédictions positives de notre modèle (avec lesquelles les 
    entrées notre modèle prédit 1). Ainsi, on a pu regarder dans les cas où les prédictions sont 0 
    et les cas où les prédictions sont 1.
    On peut remarquer qu'on trouve des variables similaires à celles trouvées avec les valeurs de 
    Shapley. On retrouve notamment assez fréquemment l'attribut \textit{agg}.
    Cependant, contrairement au résultat que pouvait nous donner \textit{ShapKit}, l'attribut \textit{mois} est 
    moins représenté. Les contributions sont également plus réparties entre les attributs.
    Enfin, il semble que, comme nous avions pu l'observer avec les valeurs de Shapley, l'attribut 
    \textit{sexe\_conducteur} ait un faible impact sur la prédiction.

    \section{Premières conclusions}
    Pour ce projet nous avons cherché un dataset qui nous intéressait, et nous avons choisi celui rapportant les accidents de la route. Pourvu de 
    nombreux attributs, nous avons dû adapter leur format avant de pouvoir les analyser de manière univariée puis bivariée. Lors du premier essai, 
    nous avons fait le choix d'utiliser des arbres de décision. Ce qui nous a conduit à transformer beaucoup de nos variables en OneHot. L'accuracy 
    de ce modèle était élevée, mais il a du mal à trouver les accidents réellement mortels. Pour ce modèle, nous avons par la suite calculé le base 
    rate puis effectué quelques audites tels que dice, BlackBoxAuditing et shapkit.

    Par la suite nous avons essayé de trouver un classifieur qui avait de meilleures performances, c'est ainsi que nous avons trouvé GaussianNB, qui
    est meilleur pour détecter les véhicules impliqués dans des accidents vraiment mortels. Pour ce modèle nous avons aussi effectué les audits 
    évoqués précédemment, mais nous ne les avons pas analysés dans ce rapport. Ce qui conclut notre premier rendu. 

    L'analyse des données puis les audits que nous avons effextués après entrainement du modèle nous ont permis d'identifier 
    plusieurs attributs sensibles. D'abord nous pensions que le genre du conducteur pourrait avoir un impact sur la prédiction. 
    Cela aurait été un biais de notre modèle. Or nous avons pu observer via les différents outils utilisés que le genre du 
    conducteur a un impact très faible sur la prédiction du modèle. En revanche, le travail effectué nous a permis d'identifier 
    d'autres attributs sensibles qui eux ont réel impact sur les sorties du modèle. Les attributs \textit{âge}, \textit{dep} et 
    \textit{mois} sont des attributs que nous avons identifié comme sensibles pour notre modèle. Ils ont un impact assez important 
    sur les prédictions et pourtant ne devraient pas être décisifs dans la classification d'un accident mortel ou non mortel.

    \section{Une réflexion pour la suite}
    Cette première partie nous a permis de nous familiariser avec notre jeu de données. L'objectif de classification a été une 
    question qui nous a suivi du début de ce projet jusqu'à la rédaction de ce rapport. 
    Les premières conclusions nous ont mené encore une fois à la réflexion sur une nouvelle direction à suivre pour la classification. 
    Ne faudrait-il pas classifier l'ensemble des 
    gravité ? Nous nous basons dans cette première partie sur des données dans lesquelles nous avons seulement 5\% d'accidents 
    mortels. Ne serait-il pas judicieux de prendre en compte l'ensemble de gravité et donc de travailler sur des proportions 
    plus conséquentes ?

    Ces questions seront déterminantes pour la suite de ce projet.

    \newpage
    \part{Correction des biais}

    \section{Améliorations du modèle}
    Cette deuxième partie du projet a commencé par l'amélioration des premiers resultats. Nous allons parcourir 
    dans cette section les différentes amélioration effectuées avant d'arriver à la correction des biais.

    \subsection{Nouvelle métrique de base : taux d'erreur et de justesse}

    Afin de trouver l'attribut à protèger et pour mieux diagnostiquer les effets des diférentes méthodes de réductions de
    biais, nous avons mis en place une nouvelle métrique de base. En tout il y a 4 caluls : 

    \begin{itemize}
        \item Taux d'\textbf{erreur} pour l'attribut \textbf{sensible} : \[ P(\overline{Y}=1| (Y=0, Z=1)) \]
        \item Taux d'\textbf{erreur} pour l'attribut \textbf{privilégié} : \[ P(\overline{Y}=1| (Y=0, Z=0)) \]
        \item Taux de \textbf{justesse} pour l'attribut \textbf{sensible} : \[ P(\overline{Y}=1| (Y=1, Z=1)) \]
        \item Taux de \textbf{justesse} pour l'attribut \textbf{privilégié} : \[ P(\overline{Y}=1| (Y=1, Z=0)) \]
    \end{itemize}

    Seules, ces métriques n'ont que peu d'intérêt, c'est lorsqu'on les regarde ensemble qu'elles prennent tout leur intérêt pour 
    la Fairness. En effet, l'équité est garantie si la différence entre ces taux pour l'attribut senseible et l'attribut privilégié 
    est nulle. En effet on serait en droit de s'attendre à ce que la justesse et l'erreur se produise dans les même proportions. 
    Notons pour finir que la liste des taux de succès est incomplète, on aurait pu ajouter le cas "\overline{Y}=0| Y=0", mais ce n'est pas ce qui 
    nous intéresse le plus dans notre cas. On souhaite se concentrer sur les prédictions d'accidents mortels.

    \subsection{Sur-échantillonnage}
    Le pré-traitement des données a été amélioré avec l'utilisation de l'outil de sur-échantillonnage \textit{SMOTE}.
    Nous avions pu remarquer lors de l'analyse de nos données que les accidents mortels sont minoritaires (environ $5\%$).
    Cet outil nous permet de rééquilibrer les classes afin d'avoir un meilleur apprentissage sur la classe des accidents 
    mortels. Le \textit{SMOTE} va générer de nouveaux individus minoritaires qui ressemblent à ceux déjà présents sans 
    pour autant être identiques.
    Nous pouvons voir sur la figure \ref{fig:smote1} que le rééquilibrage nous donne 50\% pour chaque classe 
    tout en affectant peu les proportions sur les autres attributs comme nous le montre la figure \ref{fig:smote2} 
    qui prend pour exemple l'attribut \textit{sexe\_conducteur}.
    Les résultats observés dans la suite du projet sont bien plus concluants en utilisant cette méthode.
    Tous les résultats obtenus dans la suite utilisent donc cette méthode lors du prétraitement.
    \\\\
    \begin{figure}[!h]
        \vspace{2cm}
        \centering
        \begin{subfigure}{7cm}
            \includegraphics[width=7cm]{./img/smote/before.png}
            \caption{Accidents mortels avant SMOTE}\label{fig:before_smote}
        \end{subfigure}
        \hspace{0.2cm}
        \begin{subfigure}{7cm}
            \includegraphics[width=7cm]{./img/smote/after.png}
        \caption{Accidents mortels après SMOTE}\label{fig:after_smote}
        \end{subfigure}
        \caption{Accidents mortels avant/après SMOTE}\label{fig:smote1}
    \end{figure}
    \vspace{1cm}
    \begin{figure}[h]
        \centering
        \begin{subfigure}{6cm}
            \includegraphics[width=6cm]{./img/smote/sex_before.png}
            \caption{Homme/Femme avant SMOTE}\label{fig:before_smote_sex}
        \end{subfigure}
        \vspace{\floatsep}
        \hspace{0.4cm}
        \begin{subfigure}{6cm}
            \includegraphics[width=6cm]{./img/smote/sex_after.png}
        \caption{Homme/Femme après SMOTE}\label{fig:after_smote_sex}
        \end{subfigure}
        \caption{Proportion Homme/Femme avant et après SMOTE}\label{fig:smote2}
    \end{figure}
    \vspace{1cm}

    \subsection{\textit{Random Forest Classifier}}
    La première partie de ce projet utilisait un \textit{Decision Tree Classifier}.
    Afin d'avoir un modèle plus robuste, nous avons décidé d'utiliser une forêt aléatoire.
    À première vue, les résultats étaient bien moins bons. En effet le nombre de 
    vrais positifs est très faible. Cependant, en modifiant le seuil d'acceptation on 
    peut faire évoluer la quantité de vrais positifs et obtenir des résultats bien plus 
    intéressants. Une classe a été créée afin de surcharger la méthode \verb|predict| de 
    la classe \textit{RandomForestClassifier}. Le seuil a été fixé dans un premier temps à 
    $0.2$. Nous verrons dans la suite comment régler ce seuil afin de réduire au maximum les 
    biais.

    \subsection{Attributs sensibles}
    L'analyse du nouveau modèle nous a mené à de nouvelles observations. D'abord, nous avons 
    remarqué une réduction du disparate impact pour le sexe féminin. De plus, les différents 
    outils d'évaluation des biais nous montrent tous que le sexe féminin est plus disciminé sur 
    ce modèle. L'utilisation de ce modèle a également eu pour effet de réduire l'influence de 
    l'âge, le mois et le département, ce qui est un point positif. Nous pouvons notamment 
    l'observer au travers des valeurs 
    de Shapley obtenues avec ce nouveau modèle. 
    
    Dans la suite de ce projet nous nous penchons 
    donc sur la correction des biais de l'attribut \textit{sexe\_conducteur}.



    \section{Pre-processing}
    \subsection{Repondération}
    Dans le contexte de la Frainess, la repondération a pour objectif de rééquilibrer le set d'entrainement
    en attribuant des poids différents à chaque instance. Ce poid est calculé en fonction de l'impact 
    que cette instance a sur l'attribut sensible. 
    Après apprentissage et observation des résultats de notre modèle, nous pouvons faire deux 
    observations. Premièrement les métriques de fairness sont très positives. Le disparate impact 
    passe de $0.50$ à $0.94$ pour les femmes. La seconde observation est que l'accuracy de notre 
    modèle a en revanche diminuée de $0.87$ à $0.75$. Cela peut s'expliquer par une augmentation 
    du nombre de faux positifs. En revanche un point intéressant est que le nombre de 
    vrais positifs est ici plus élevé que le nombre de positifs prédits faux, ce qui n'était pas 
    le cas sur les modèles testés jusqu'ici.
    La matrice de confusion (figure \ref{fig:reweight_matrix}) nous montre 
    les résultats obtenus après repondération. Un effet intéressant de cette intervention sur le set d'entrainement
    est que le modèle parvient mieux à trouver les morts vraiment mort qu'auparavant. La baisse en accuracy s'explique
    par l'augmentation d'erreur de détection des accidents qui auraient du être labelisé accidents non - mortels. En
    résumé ce nouveau modèle catégorise trop d'accidents comme étant mortels. Mais parmi les accidents détectés comme
    étant mortels seul un sur huit l'est vraiment. Dans notre cas c'est intéressant car dans un objectif de prévention
    routière, on veut écarter les causes d'accidents non mortels des campagnes de sécurité pour augmenter leur efficacité.

    \begin{figure}[h]
        \centering
        \includegraphics[width=11cm]{./img/confusion_matrix_reweight.png}
        \caption{Matrice de confusion avec repondération}
        \label{fig:reweight_matrix}
    \end{figure}

    \subsection{Disparate Impact Remover}
    Les résultats obtenus avec le \textit{Disparate impact remover} sont similaires à ceux obtenus avec 
    la repondération. On obtient une accuracy de $0.75$ et un disparate impact de $0.89$. Le disparate 
    impact est un peu moins bon que celui obtenu avec la repondération pour une accuracy équivalente.
    On peut remarquer que tout comme avec la repondération, la matrice de confusion nous montre une 
    tendance allant vers plus de faux positifs. On remarque également encore une amélioration des prédictions 
    de vrais positifs qui est très proche de celle obtenue par la méthode précédente. 
    Ci-dessou la matrice de confusion (figure \ref{fig:DIR_matrix}) du modèle utilisant le disparate impact remover.

    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{./img/DIR_confusion_matrix.png}
        \caption{Matrice de confusion avec Disparate Impact Remover}
        \label{fig:DIR_matrix}
    \end{figure}


    \subsection{Représentation latente fair}
    

    \section{In-processing}

    \subsection{Adversarial debiasing}

    \section{Post-processing}

    \subsection{Reject option classification}
    \subsubsection{Un nouveau seuil}

    Le but de cette méthode de correction de biais post-preprocessing, est de faire varier le seuil de décision de manière à 
    trouver celui qui a la meilleure fairness, pour le comparer au seuil ayant la meilleure accuracy.

    Toujours à l'aide d'AIF 360, nous avons utiliser ROC en paramétrant le groupe privilégié à 1 (Hommes) et les lésés à 0 (Femmes).
    Les résultat sont les suivant: 

    \begin{itemize}
        \item Sans fairness : \textit{0.1189}
        \item Avec fairness : \textit{0.1289}
    \end{itemize}
    
    De ces résultats on peut sortir deux observations. Tout d'abord, ROC à resenti le besoin de déplacer le seuil de sorte à corriger 
    le biais. Ensuite, la correction effectuée est minime dans son ampleur. 

    \subsubsection{Les nouvelles performances du modèle}

    Les répercussions sur l'accuracy quand à elles sont notables mais acceptables. On passe en effet de \textit{0,876} à \textit{0,790}.
    Cependant, si on regarde un peu plus en détail la matrice de confusion, il parrait intéressant de noter que ce modèle détecte mieux 
    les accidents mortels véritablement mortels. Pour être précis, ce nombre passe de \textit{660} à \textit{1044} ce qui constitue  \textit{62\%} des accidents
    mortels répertoriés dans l'ensemble. Ceci se fait au prix d'un augmentation des accidents non motrtels faussement détectés. Malgré tout, 
    le taux de détection de ce type d'accident reste élevé à \textit{80\%}. Voilà pourquoi la qualification d'acceptable pour la baisse en 
    accuracy est parfaitement adaptée.

    \subsubsection{Les performances pour la Fairness}

    La première observation que l'on peut faire, c'est que le disparate impact se voit corrigé pour les femmes. Pour être précis, avec le nouveau seuil, le disparate impact
    augmente à \textit{0.640} là ou celui des hommes est à \textit{0.636}. Il s'est donc à la fois presque aligné à celui des hommes tout en se rapprochant de 1. 
    
    On remarque aussi que les taux d'erreur 
    \[ P(\overline{Y}=1| (Y=1, Z=0)) \] \[ P(\overline{Y}=1| (Y=0, Z=0)) \] \[ P(\overline{Y}=1| (Y=1, Z=1)) \] \[ P(\overline{Y}=1| (Y=0, Z=1)) \] chez les femmes se sont rapprochés de
    ceux des hommes. Cela qui atteste d'une correction de biais substentielle.  

    En revanche, il faut sousligner que la correction de biais n'est pas complète. On peut même dire qu'elle est inférieure à d'autres méthodes telles que reweighing.
    
    \subsection{Calibrated equalized odds}
    
    \section{Résultats}

    \section{Conclusion}

    \newpage
    \appendix

    \section{Les données conservées pour le modèle.}\label{appendix:dataset}
    \begin{center}
        \begin{tabular}{ |c|p{9cm}| }
            \hline
            \textbf{Attribut} & \textbf{Description} \\
            \hline
            \textit{Num\_Acc} & Numéro d'identifiant de l'accident \\
            \textit{jour mois} & Jour de l'accident, mois de l'accident \\
            \textit{an} & Année de l'accident \\
            \textit{hrmn} & Heure et minutes de l'accident \\
            \textit{lum} & Conditions d'éclairage dans lesquelles l'accident s'est produit \\
            \textit{dep} & Code INSEE du département \\
            \textit{agg} & Localisation en agglomération \\
            \textit{int} & Type d'intersection \\
            \textit{atm} & Conditions atmosphériques \\
            \textit{col} & Type de collision \\
            \textit{adr} & Adresse postale (pour les accidents en agglomération) \\
            \textit{lat} & Latitude \\
            \textit{long} & Longitude \\
            \textit{catr} & Catégorie de route \\
            \textit{voie} & Numéro de la route \\
            \textit{circ} & Régime de circulation \\
            \textit{nbv} & Nombre total de voies de circulation \\
            \textit{vosp} & Présence d'une voie réservée \\
            \textit{prof} & Profil en long de la route \\
            \textit{plan} & Tracé en plan de la route \\
            \textit{surf} & État de la surface de la route \\
            \textit{infra} & Présence d'aménagements ou d'infrastructures \\
            \textit{situ} & Situation géographique de l'accident \\
            \textit{vma} & Vitesses maximale autorisées \\
            \textit{id\_vehicule} & Identifiant du véhicule (clé étrangère) \\
            \textit{catv} & Catégorie du véhicule impliqué dans l'accident \\
            \textit{obs} & Type d'obstacle heurté \\
            \textit{obsm} & Type d'obstacle mobile heurté \\
            \textit{choc} & Point de choc initial \\
            \textit{manv} & Manœuvre principale avant l'accident \\
            \textit{catu} & Catégorie d'usager (conducteur, passager, piéton) \\
            \textit{grav} & Gravité de l'accident pour l'usager \\
            \textit{sexe} & Sexe du conducteur \\
            \textit{trajet} & Motif du déplacement au moment de l'accident \\
            \textit{mortal} & Indique si le véhicule est impliqué dans un accident mortel (calculé dans le notebook) \\
            \hline
        \end{tabular}
    \end{center}
    \newpage

    \section{Les données abandonées et la raison de leur abandon}\label{appendix:dataset}
    \begin{center}
        \begin{tabular}{ |c|p{4.5cm}|p{4.5cm} }
            \hline
            \textbf{Attribut} & \textbf{Description} & \textbf{Raison de l'abaodon} \\
            \hline
            \textit{id\_vehicule} & identifiant numérique unique du véhicule & information administrative, une fois les tables jointe, cette inforamtion sans intétret, n'est plus utile\\
            \textit{num\_veh} & identifiant du véhicule pour associer les passager du même vehicule & information administrative, une fois les tables jointe, cette inforamtion sans intétret, n'est plus utile\\
            \textit{id\_usager} & identifiant des usagers dans la base & utilisé lors des jointures, inutile par la suite\\
            \textit{com} & Numéro de commune (code INSEE) & commune trop spécifique, ça donne trop de catégories\\
            \textit{adr} & adresse de l'accident & trop spécifique, ne donne rien de pertinent\\
            \textit{lat} & latitude de l'accident & Ces informations positionelles ne reflètenet pas le type d'endroit où l'accident a lieu\\
            \textit{Long} & longitude de l'accident & Ces informations positionelles ne reflètenet pas le type d'endroit où l'accident a lieu\\
            \textit{Num\_Acc} & Numéro d'identifiant de l'accident & information administrative, une fois les tables jointe, cette inforamtion sans intétret, n'est plus utile\\
            \textit{voie} & Numéro de la route & pas pertinent, plusieurs routes ont le même numéro, les routes ont des sections plus dangereuses que d'autres\\
            \textit{V1} & Numéro de la route & pas pertinent, plusieurs routes ont le même numéro, les routes ont des sections plus dangereuses que d'autres\\
            \textit{V2} & Numéro de la route & pas pertinent, plusieurs routes ont le même numéro, les routes ont des sections plus dangereuses que d'autres\\
            \textit{vosp} & Signale l’existence d’une voie réservée, indépendamment du fait que l’accident ait lieu ou non sur cette voie. & attribut trop peu renseigné, peu d'accidents concerné\\
            \textit{pr} & numéro de la borne (routière) en amont  & pas pertinent, beaucoup de routes sont non bornées, n'indique rien d'intéressant sur l'accident\\
            \textit{pr1} & Distance en mètres à la borne en amont &  pas pertinent, beaucoup de routes sont non bornées, n'indique rien d'intéressant sur l'accident\\
            \textit{lartpc} & largeur terplein central en m & trop peu renseigné\\
            \textit{larrout} & largeur de la chaussée en m & trop peu renseigné\\
            \textit{senc} & indique si le véhicule allait vèrs une borne supérieure ou inférieure à la précédente. & information administrative, pas utile\\
            \textit{manv} & indique la manoeuvre en cours au moment de l'accident & trop souvent inconnue ou non renseignée\\
            \textit{motor} & motoriqation du véhicule & trop peu renseigné\\
            \textit{place} & place du passager dans l'habitacle, 10 indique un piéton & utilisé pour trouver les conducteurs et les piétons, devient inutile à l'échelle de l'accident ensuite\\
            \textit{grav} & donne l'état de grévité de l'usager accidenté & utilisé pour trouver les accidents mortels, devient inutile à l'échelle de l'accident ensuite\\
            \textit{sexe} & sexe de l'usager (binaire) & utilisé pour déterminé le sexe du conducteur, devient inutile à l'échelle de l'accident ensuite\\
            \textit{secu1, secu2, secu3} & trois attributs renseignant tous les 3 sur l'utilisation d'équipements de sécutrité & attribut difficilement implémentable et peu fiable car non reiseigné apparait beaucoup\\
            \textit{locp} & Localisation du piéton par rapport au véhicule & le point de vue de l'accident rend difficile l'mplémentation de cet attribut peu renseigné\\
            \textit{actp} & Action piétion lors de l'accident & le point de vue de l'accident rend difficile l'mplémentation de cet attribut peu renseigné\\
            \textit{etatp} & précise précise si le pieton était accompagné & le point de vue de l'accident rend difficile l'mplémentation de cet attribut peu renseigné\\
            \textit{occutc} & nombre d'occupant du transporte ne commun & cet attribut est trop peu renseigné\\
            \textit{jour} & numéro du jour de l'accident & peu utile, il aurait été plus utile de connaitre le jours de la semaine\\
            \textit{hrmn} & heures : minutes & format non adapté, redondant de luninosité (lum) qui est plus précis\\
            \textit{an} & année de l'accident & utilisé pour déterminer l'age du conducteur, n'est plus utile par la suite \\
            \textit{an\_nais} & année de naissance de l'usager & utilisé pour déterminer l'age du conducteur, n'est plus utile par la suite, pas adapté au point de vue de l'accident \\
            \hline
        \end{tabular}
    \end{center}
    \newpage

    \section{Diagrammes en cascade des valeurs de Shapley}
    \begin{figure}[ht]
        \centering
        \begin{subfigure}{9cm}
            \includegraphics[width=9cm]{./img/shap10.png}
            \caption{}
        \end{subfigure}
        \begin{subfigure}{9cm}
            \includegraphics[width=9cm]{./img/shap8.png}
        \caption{}
        \end{subfigure}
        \begin{subfigure}{9cm}
            \includegraphics[width=9cm]{./img/shap9.png}
        \caption{}
        \end{subfigure}
    \end{figure}
    \begin{figure}[ht]
        \centering
        \begin{subfigure}{9cm}
            \includegraphics[width=9cm]{./img/shap7.png}
            \caption{}
        \end{subfigure}
        \begin{subfigure}{9cm}
            \includegraphics[width=9cm]{./img/shap6.png}
        \caption{}
        \end{subfigure}
        \begin{subfigure}{9cm}
            \includegraphics[width=9cm]{./img/shap5.png}
        \caption{}
        \end{subfigure}
    \end{figure}

\end{document}